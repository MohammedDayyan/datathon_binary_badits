{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Dehazing Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the complete image dehazing pipeline for Indian winter conditions.\n",
    "\n",
    "## Features:\n",
    "- Multiple dehazing models (AOD-Net, DehazeNet, MSBDN)\n",
    "- Haze generation for testing\n",
    "- Comprehensive evaluation metrics\n",
    "- Hallucination detection\n",
    "- Interactive web dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path().absolute().parent / \"src\"))\n",
    "\n",
    "from src.inference import DehazeInferencePipeline\n",
    "from src.haze_generator import HazeGenerator\n",
    "from evaluation.metrics import DehazeMetrics\n",
    "from evaluation.evaluator import DehazeEvaluator\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize inference pipeline\n",
    "pipeline = DehazeInferencePipeline()\n",
    "print(\"Loading models...\")\n",
    "pipeline.initialize_models()\n",
    "\n",
    "# Get model information\n",
    "model_info = pipeline.get_model_info()\n",
    "print(f\"Available models: {model_info['available_models']}\")\n",
    "print(f\"Device: {model_info['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Haze Generation (Bonus Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize haze generator\n",
    "haze_generator = HazeGenerator()\n",
    "\n",
    "# Load a clear image (replace with your image path)\n",
    "clear_image_path = \"../data/sample_clear.jpg\"  # Replace with actual path\n",
    "\n",
    "# For demo, create a sample image if not available\n",
    "if not os.path.exists(clear_image_path):\n",
    "    print(\"Creating sample clear image...\")\n",
    "    sample_image = Image.new('RGB', (512, 512), color='skyblue')\n",
    "    # Add some simple content\n",
    "    import numpy as np\n",
    "    img_array = np.array(sample_image)\n",
    "    # Add some shapes\n",
    "    img_array[100:200, 100:200] = [255, 0, 0]  # Red square\n",
    "    img_array[300:400, 300:400] = [0, 255, 0]  # Green square\n",
    "    sample_image = Image.fromarray(img_array)\n",
    "    sample_image.save(clear_image_path)\n",
    "    print(f\"Sample image saved to {clear_image_path}\")\n",
    "\n",
    "# Generate different types of haze\n",
    "haze_types = ['light', 'moderate', 'heavy', 'extreme']\n",
    "hazy_images = {}\n",
    "\n",
    "for haze_type in haze_types:\n",
    "    # Load clear image\n",
    "    clear_img = Image.open(clear_image_path).convert('RGB')\n",
    "    clear_array = np.array(clear_img)\n",
    "    \n",
    "    # Generate haze\n",
    "    hazy_array = haze_generator.generate_composite_haze(clear_array, haze_type)\n",
    "    hazy_images[haze_type] = Image.fromarray(hazy_array)\n",
    "    \n",
    "    # Save hazy image\n",
    "    hazy_path = f\"../data/hazy_{haze_type}.jpg\"\n",
    "    hazy_images[haze_type].save(hazy_path)\n",
    "    print(f\"Generated {haze_type} haze: {hazy_path}\")\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "axes[0].imshow(clear_img)\n",
    "axes[0].set_title('Clear Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, haze_type in enumerate(haze_types):\n",
    "    axes[i+1].imshow(hazy_images[haze_type])\n",
    "    axes[i+1].set_title(f'{haze_type.capitalize()} Haze')\n",
    "    axes[i+1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Dehazing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a hazy image for dehazing\n",
    "hazy_image_path = \"../data/hazy_moderate.jpg\"  # Use generated haze\n",
    "\n",
    "# Test all models\n",
    "models = model_info['available_models']\n",
    "dehazed_results = {}\n",
    "\n",
    "print(\"Dehazing with different models...\")\n",
    "for model_name in models:\n",
    "    print(f\"Processing with {model_name}...\")\n",
    "    \n",
    "    output_path = f\"../data/dehazed_{model_name}.jpg\"\n",
    "    result = pipeline.dehaze_single_image(hazy_image_path, model_name, output_path)\n",
    "    \n",
    "    if result['success']:\n",
    "        dehazed_results[model_name] = {\n",
    "            'image': Image.open(output_path),\n",
    "            'result': result\n",
    "        }\n",
    "        print(f\"  ✓ Success - Time: {result['processing_time']:.2f}s\")\n",
    "        if result['metrics'].get('psnr'):\n",
    "            print(f\"    PSNR: {result['metrics']['psnr']:.2f} dB\")\n",
    "        if result['metrics'].get('ssim'):\n",
    "            print(f\"    SSIM: {result['metrics']['ssim']:.4f}\")\n",
    "    else:\n",
    "        print(f\"  ✗ Failed: {result['error']}\")\n",
    "\n",
    "# Display comparison\n",
    "if dehazed_results:\n",
    "    fig, axes = plt.subplots(1, len(models) + 2, figsize=(15, 3))\n",
    "    \n",
    "    # Original clear\n",
    "    axes[0].imshow(clear_img)\n",
    "    axes[0].set_title('Original Clear')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Hazy\n",
    "    hazy_img = Image.open(hazy_image_path)\n",
    "    axes[1].imshow(hazy_img)\n",
    "    axes[1].set_title('Hazy Input')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Dehazed results\n",
    "    for i, model_name in enumerate(models):\n",
    "        if model_name in dehazed_results:\n",
    "            axes[i+2].imshow(dehazed_results[model_name]['image'])\n",
    "            axes[i+2].set_title(f'{model_name.upper()}')\n",
    "            axes[i+2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics calculator\n",
    "metrics_calc = DehazeMetrics()\n",
    "\n",
    "# Calculate comprehensive metrics for each model\n",
    "from torchvision import transforms\n",
    "\n",
    "clear_tensor = transforms.ToTensor()(clear_img)\n",
    "hazy_tensor = transforms.ToTensor()(hazy_img)\n",
    "\n",
    "print(\"Metrics Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<12} {'PSNR':<8} {'SSIM':<8} {'MAE':<8} {'Time(s)':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Hazy baseline metrics\n",
    "hazy_metrics = metrics_calc.calculate_all_metrics(hazy_tensor, clear_tensor)\n",
    "print(f\"{'Hazy':<12} {hazy_metrics['psnr']:<8.2f} {hazy_metrics['ssim']:<8.4f} {hazy_metrics['mae']:<8.4f} {'N/A':<8}\")\n",
    "\n",
    "# Model results\n",
    "for model_name, data in dehazed_results.items():\n",
    "    dehazed_tensor = transforms.ToTensor()(data['image'])\n",
    "    metrics = metrics_calc.calculate_all_metrics(dehazed_tensor, clear_tensor)\n",
    "    time_val = data['result']['processing_time']\n",
    "    \n",
    "    print(f\"{model_name:<12} {metrics['psnr']:<8.2f} {metrics['ssim']:<8.4f} {metrics['mae']:<8.4f} {time_val:<8.3f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Visual comparison of metrics\n",
    "if len(dehazed_results) > 1:\n",
    "    models_list = list(dehazed_results.keys())\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    for model_name in models_list:\n",
    "        dehazed_tensor = transforms.ToTensor()(dehazed_results[model_name]['image'])\n",
    "        metrics = metrics_calc.calculate_all_metrics(dehazed_tensor, clear_tensor)\n",
    "        psnr_values.append(metrics['psnr'])\n",
    "        ssim_values.append(metrics['ssim'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.bar(models_list, psnr_values)\n",
    "    ax1.set_title('PSNR Comparison')\n",
    "    ax1.set_ylabel('PSNR (dB)')\n",
    "    \n",
    "    ax2.bar(models_list, ssim_values)\n",
    "    ax2.set_title('SSIM Comparison')\n",
    "    ax2.set_ylabel('SSIM')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hallucination Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import HallucinationDetector\n",
    "\n",
    "# Initialize hallucination detector\n",
    "hallucination_detector = HallucinationDetector()\n",
    "\n",
    "print(\"Hallucination Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for model_name, data in dehazed_results.items():\n",
    "    dehazed_tensor = transforms.ToTensor()(data['image'])\n",
    "    \n",
    "    # Detect hallucination indicators\n",
    "    indicators = hallucination_detector.detect_structure_changes(\n",
    "        hazy_tensor, dehazed_tensor, clear_tensor\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(f\"  Edge Preservation Improvement: {indicators['edge_preservation_improvement']:.4f}\")\n",
    "    print(f\"  Texture Similarity Change: {indicators['texture_similarity_change']:.4f}\")\n",
    "    print(f\"  Color Consistency: {indicators['color_consistency']:.4f}\")\n",
    "    print(f\"  Hallucination Score: {indicators['hallucination_score']:.4f} (lower is better)\")\n",
    "    \n",
    "    # Interpretation\n",
    "    score = indicators['hallucination_score']\n",
    "    if score < 0.3:\n",
    "        assessment = \"Low hallucination risk\"\n",
    "    elif score < 0.6:\n",
    "        assessment = \"Moderate hallucination risk\"\n",
    "    else:\n",
    "        assessment = \"High hallucination risk\"\n",
    "    \n",
    "    print(f\"  Assessment: {assessment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Web Dashboard Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about web dashboard\n",
    "print(\"Web Dashboard Information:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"To start the interactive web dashboard:\")\n",
    "print()\n",
    "print(\"1. From command line:\")\n",
    "print(\"   python main.py web\")\n",
    "print()\n",
    "print(\"2. Or directly with Streamlit:\")\n",
    "print(\"   streamlit run web/app.py\")\n",
    "print()\n",
    "print(\"3. Then open: http://localhost:8501\")\n",
    "print()\n",
    "print(\"Features:\")\n",
    "- Upload hazy images\n",
    "- Choose dehazing model\n",
    "- Real-time processing\n",
    "- Download results\n",
    "- Model comparison\n",
    "- Batch processing\n",
    "- Metrics display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Pipeline Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete demo: Clear -> Haze -> Dehaze\n",
    "print(\"Complete Pipeline Demo\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Step 1: Start with clear image\n",
    "print(\"Step 1: Original clear image\")\n",
    "display(clear_img)\n",
    "\n",
    "# Step 2: Add haze\n",
    "print(\"\\nStep 2: Adding moderate haze...\")\n",
    "hazy_array = haze_generator.generate_composite_haze(np.array(clear_img), 'moderate')\n",
    "hazy_demo = Image.fromarray(hazy_array)\n",
    "display(hazy_demo)\n",
    "\n",
    "# Step 3: Dehaze with best model\n",
    "print(\"\\nStep 3: Dehazing with best performing model...\")\n",
    "\n",
    "# Find best model based on PSNR\n",
    "best_model = None\n",
    "best_psnr = -float('inf')\n",
    "\n",
    "for model_name, data in dehazed_results.items():\n",
    "    dehazed_tensor = transforms.ToTensor()(data['image'])\n",
    "    metrics = metrics_calc.calculate_all_metrics(dehazed_tensor, clear_tensor)\n",
    "    if metrics['psnr'] > best_psnr:\n",
    "        best_psnr = metrics['psnr']\n",
    "        best_model = model_name\n",
    "\n",
    "if best_model:\n",
    "    print(f\"Best model: {best_model} (PSNR: {best_psnr:.2f} dB)\")\n",
    "    display(dehazed_results[best_model]['image'])\n",
    "    \n",
    "    # Final metrics\n",
    "    final_metrics = metrics_calc.calculate_all_metrics(\n",
    "        transforms.ToTensor()(dehazed_results[best_model]['image']), \n",
    "        clear_tensor\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFinal Results:\")\n",
    "    print(f\"  PSNR: {final_metrics['psnr']:.2f} dB\")\n",
    "    print(f\"  SSIM: {final_metrics['ssim']:.4f}\")\n",
    "    print(f\"  MAE: {final_metrics['mae']:.4f}\")\n",
    "    print(f\"  Processing time: {dehazed_results[best_model]['result']['processing_time']:.3f}s\")\n",
    "else:\n",
    "    print(\"No successful dehazing results found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Demo completed successfully!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Try with your own images\")\n",
    "print(\"2. Experiment with different haze types\")\n",
    "print(\"3. Use the web dashboard for interactive processing\")\n",
    "print(\"4. Run full evaluation on NTIRE datasets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
